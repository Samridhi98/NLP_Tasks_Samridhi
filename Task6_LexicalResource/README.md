# Task - 6 (Samridhi Muararka 17BCE2038)

## 6.1 Exploring the Lexical resources
   1. Import stopwords from nltk library
   2. Access CMU Dcitionary from nltk.corpus as 'cmudict'. It contains over 134,000 words and their pronunciations.
   3. WORDNET lexical database, showing different forms of a similar words using 'lemma_names'
   
## 6.2 Sentence Tokenization and Pipelining
   1. Pipeling two different tokenizers on given text
   2. Sent_tokenize of nltk library tokenizes into sentences
   3. Next in pipeline is word_tokenize to split the sentences further to tokens
   
## 6.3 Twitter Tokenization
   1. Using TweetTokenizer

## Problems Faced
   "averaged_percepton_tagger" is required for use during tokenization. It's use is however unclear
