{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task - 5 (Samridhi Murarka)\n",
    "## 5.1 Webtext Corpus\n",
    "NLTK's small collection of web text includes content from a Firefox discussion forum, conversations etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firefox.txt',\n",
       " 'grail.txt',\n",
       " 'overheard.txt',\n",
       " 'pirates.txt',\n",
       " 'singles.txt',\n",
       " 'wine.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtext.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lovely',\n",
       " 'delicate',\n",
       " ',',\n",
       " 'fragrant',\n",
       " 'Rhone',\n",
       " 'wine',\n",
       " '.',\n",
       " 'Polished',\n",
       " 'leather',\n",
       " 'and',\n",
       " 'strawberries',\n",
       " '.',\n",
       " 'Perhaps',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'dilute',\n",
       " ',',\n",
       " 'but',\n",
       " 'good',\n",
       " 'for']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtext.words(fileids='wine.txt')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k= webtext.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upto 10 words from each file in webtext corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firefox.txt ['Cookie', 'Manager', ':', '\"', 'Don', \"'\", 't', 'allow', 'sites', 'that']\n",
      "grail.txt ['SCENE', '1', ':', '[', 'wind', ']', '[', 'clop', 'clop', 'clop']\n",
      "overheard.txt ['White', 'guy', ':', 'So', ',', 'do', 'you', 'have', 'any', 'plans']\n",
      "pirates.txt ['PIRATES', 'OF', 'THE', 'CARRIBEAN', ':', 'DEAD', 'MAN', \"'\", 'S', 'CHEST']\n",
      "singles.txt ['25', 'SEXY', 'MALE', ',', 'seeks', 'attrac', 'older', 'single', 'lady', ',']\n",
      "wine.txt ['Lovely', 'delicate', ',', 'fragrant', 'Rhone', 'wine', '.', 'Polished', 'leather', 'and']\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(k)):\n",
    "    print(k[i]+\" \"+str(webtext.words(fileids=k[i])[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Analysis of tweets in form of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('tweets1.txt','r')\n",
    "text=f.read()\n",
    "text1=text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2=nltk.Text(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 17 of 17 matches:\n",
      "n The Signal premiere. Lotsa buyers. Good luck gang listening to the pocast ne\n",
      "so going to enjoy this shower. Feels good to have worked on a trail three time\n",
      "ose not my friend. it was not a very good day so I have a lot to do tomorrow..\n",
      "Oh why cheesecake why? You looked so good evil cake. Now metamucil. Reading: \"\n",
      "utiful day so Im thinking to spend a good part of it outdoors.first stop at St\n",
      "g and ignoring my reaction to a very good friend getting fired. it's like a bi\n",
      "d HDH - url wrist sprain= damn pain. good thing it's not on my left hand. Bein\n",
      " I bet I can throw farther than her. Good luck with that dude. Sure it will al\n",
      " Choppers. first day of eid .. feels good Looking to buy a game called Shut th\n",
      "g. back from the ASLA 6 Congress. :) Good job ASLA CORE! I'm gonna need to ste\n",
      "tching the CNBC video of David Lear. Good job Sean! and now... off to Belize! \n",
      " Mom's cousin's car. this would be a good place for wifi! a hot technology to \n",
      "e Long Tail: Are dead-tree magazines good or bad for the climate? url the mida\n",
      "ortened! url www.last.fm is a really good idea Worst drive I've ever had. Sanj\n",
      " my tivoed shows I missed last week. Good day from fratres this 01.22.08! Ther\n",
      "ill have cause for regret. 01..24.08 Good Day!!! See Pope Benedict's plea for \n",
      ".. , @cleshen, everything went well. Good people! Probably have to go back to \n"
     ]
    }
   ],
   "source": [
    "text2.concordance(\"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Extracting data from URL / Web Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "url=\"https://www.gutenberg.org/files/2554/2554-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176967"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:74]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Tokenizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257727"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'by',\n",
       " 'Fyodor',\n",
       " 'Dostoevsky']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: ﻿The Project Gutenberg EBook of Crime and Punishment...>\n"
     ]
    }
   ],
   "source": [
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of Crime and Punishment , by Fyodor Dostoevsky \n"
     ]
    }
   ],
   "source": [
    "sent=\"\"\n",
    "for word in tokens[:12]:\n",
    "    sent+=word+\" \" \n",
    "print(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
